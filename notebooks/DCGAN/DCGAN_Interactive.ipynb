{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I99XgVHvPyev"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "!pip install lpips\n",
        "import lpips\n",
        "from skimage import color\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "#TODO: Convert from google colab to personal computer for easier usage"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If not done already, please place this script along with the DCGAN generator and any pictures you want restored in the same folder. There are noisy pictures available in the folder for use if you have no noisy images of your own."
      ],
      "metadata": {
        "id": "i7HDnFZ-Qp_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "DATASET_ROOT = \"/content/drive/MyDrive/GAN-results/lambda80_adam0.0001\"\n",
        "\n",
        "pic = input(\"Please write the name of your picture including file extension i.e. 'picture.png': \")\n",
        "\n"
      ],
      "metadata": {
        "id": "9U7FAI2XRLE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This DCGAN model has been trained on 64x64 images. Your image will be automatically resized."
      ],
      "metadata": {
        "id": "eZoXlp_7Sf1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prepare(path):\n",
        "    img = Image.open(path).convert(\"RGB\").resize((64, 64))\n",
        "\n",
        "    print(\"This is your input picture:\")\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    arr = np.array(img).astype(\"float32\")\n",
        "    arr = (arr - 127.5) / 127.5\n",
        "\n",
        "    arr = np.expand_dims(arr, axis=0)\n",
        "    return arr\n",
        "\n",
        "pic_prepared = load_and_prepare(\"/content/drive/MyDrive/GAN_results/doggo.jpg\")"
      ],
      "metadata": {
        "id": "T6tTHMLiSY44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The generator will now be loaded and given your picture for restoration."
      ],
      "metadata": {
        "id": "ztUAZOrnXjs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = tf.keras.models.load_model(\"/content/drive/MyDrive/GAN_results/lambda80_adam0.0001/generator.keras\")\n",
        "\n",
        "output = generator(pic_prepared, training=False).numpy()\n",
        "\n",
        "#Return the array to the form of a picture\n",
        "output_metrics = output #Save a normalized copy for metrics\n",
        "output = (output[0] * 127.5 + 127.5).clip(0, 255).astype(\"uint8\")\n",
        "\n",
        "print(\"This is your restored picture:\")\n",
        "plt.imshow(output)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2hoDUqn9XWu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_msssim(original, restored):\n",
        "    original = (original + 1)/2\n",
        "    restored = (restored + 1)/2\n",
        "    original = tf.convert_to_tensor(original, dtype=tf.float32)\n",
        "    restored = tf.convert_to_tensor(restored, dtype=tf.float32)\n",
        "\n",
        "    return tf.image.ssim_multiscale(original, restored, max_val=1.0, filter_size=3).numpy()\n",
        "\n",
        "compare = lpips.LPIPS(net='alex')\n",
        "\n",
        "def metrics_lpips(original, restored):\n",
        "    t1 = torch.tensor(original).permute(0, 3, 1, 2)\n",
        "    t2 = torch.tensor(restored).permute(0, 3, 1, 2)\n",
        "    return compare(t1, t2).item()\n",
        "\n",
        "def metrics_deltaE2000(original, restored):\n",
        "    original = (original + 1)/2\n",
        "    restored = (restored + 1)/2\n",
        "    scale1 = color.rgb2lab(original)\n",
        "    scale2 = color.rgb2lab(restored)\n",
        "    delta = color.deltaE_ciede2000(scale1, scale2)\n",
        "    return np.mean(delta)\n",
        "\n",
        "value_msssim = metrics_msssim(pic_prepared, output_metrics)\n",
        "value_lpips = metrics_lpips(pic_prepared, output_metrics)\n",
        "value_deltaE = metrics_deltaE2000(pic_prepared, output_metrics)\n",
        "\n",
        "print(value_msssim)\n",
        "print(value_lpips)\n",
        "print(value_deltaE)"
      ],
      "metadata": {
        "id": "fLgWpF9RbDTF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}