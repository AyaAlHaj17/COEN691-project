{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNzlWKtnTY9FJIjTsh6mcFT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyaAlHaj17/COEN691-project/blob/main/notebooks/DnCNN/DnCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_ly7qTCIbFF"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install -q datasets huggingface_hub pillow torch torchvision tqdm requests\n",
        "!pip install -q pytorch-lightning wandb scikit-image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "print(\"Loading HQ-50K dataset from Hugging Face...\")\n",
        "dataset = load_dataset(\"YangQiee/HQ-50K\", split=\"train\")\n",
        "print(f\"Dataset loaded successfully! Total images: {len(dataset)}\")\n",
        "\n",
        "print(f\"Dataset columns: {dataset.column_names}\")\n",
        "print(f\"First example keys: {dataset[0].keys()}\")\n",
        "\n",
        "\n",
        "def add_gaussian_noise(image, noise_level=25):\n",
        "    \"\"\"Add Gaussian noise to image\"\"\"\n",
        "    noise = torch.randn_like(image) * (noise_level / 255.0)\n",
        "    noisy = image + noise\n",
        "    return torch.clamp(noisy, 0, 1)\n",
        "\n",
        "def jpeg_compression(image, quality=10):\n",
        "    \"\"\"Simulate JPEG compression artifacts\"\"\"\n",
        "    import io\n",
        "    from torchvision.transforms.functional import to_pil_image, to_tensor\n",
        "\n",
        "    pil_img = to_pil_image(image)\n",
        "    buffer = io.BytesIO()\n",
        "    pil_img.save(buffer, format='JPEG', quality=quality)\n",
        "    buffer.seek(0)\n",
        "    compressed = Image.open(buffer)\n",
        "    return to_tensor(compressed)\n",
        "\n",
        "def downsample_image(image, scale_factor=4):\n",
        "    \"\"\"Downsample image for super-resolution\"\"\"\n",
        "    h, w = image.shape[1:]\n",
        "    lr_h, lr_w = h // scale_factor, w // scale_factor\n",
        "    lr_image = F.interpolate(image.unsqueeze(0), size=(lr_h, lr_w),\n",
        "                             mode='bicubic', align_corners=False)\n",
        "    return lr_image.squeeze(0)\n",
        "\n",
        "def add_rain_streaks(image, num_streaks=100):\n",
        "    \"\"\"Add synthetic rain streaks\"\"\"\n",
        "    img_copy = image.clone()\n",
        "    c, h, w = img_copy.shape\n",
        "\n",
        "    for _ in range(num_streaks):\n",
        "        x = random.randint(0, w - 1)\n",
        "        y = random.randint(0, h - 20)\n",
        "        length = random.randint(10, 20)\n",
        "        thickness = random.randint(1, 2)\n",
        "        brightness = random.uniform(0.3, 0.7)\n",
        "\n",
        "        for i in range(length):\n",
        "            if y + i < h:\n",
        "                x_pos = min(x + random.randint(-1, 1), w - 1)\n",
        "                for t in range(thickness):\n",
        "                    if x_pos + t < w:\n",
        "                        img_copy[:, y + i, x_pos + t] = brightness\n",
        "\n",
        "    return img_copy\n",
        "\n",
        "\n",
        "\n",
        "class ImageRestorationDataset(Dataset):\n",
        "    def __init__(self, hf_dataset, degradation_type='denoise',\n",
        "                 transform=None, subset_size=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hf_dataset: Hugging Face dataset with image URLs\n",
        "            degradation_type: 'denoise', 'dejpeg', 'super_resolution', 'derain'\n",
        "            transform: Image transformations\n",
        "            subset_size: Use subset of data (for faster training)\n",
        "        \"\"\"\n",
        "        self.dataset = hf_dataset\n",
        "        self.degradation_type = degradation_type\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.Resize((256, 256)),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "        if subset_size and subset_size < len(hf_dataset):\n",
        "            indices = random.sample(range(len(hf_dataset)), subset_size)\n",
        "            self.dataset = self.dataset.select(indices)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        from io import BytesIO\n",
        "        import requests\n",
        "\n",
        "        max_retries = 3\n",
        "\n",
        "\n",
        "        item = self.dataset[idx]\n",
        "\n",
        "\n",
        "        if 'url' in item:\n",
        "            image_url = item['url']\n",
        "        elif 'image_url' in item:\n",
        "            image_url = item['image_url']\n",
        "        elif isinstance(item, dict) and len(item) == 1:\n",
        "            image_url = list(item.values())[0]\n",
        "        else:\n",
        "            for value in item.values():\n",
        "                if isinstance(value, str) and value.startswith('http'):\n",
        "                    image_url = value\n",
        "                    break\n",
        "\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                response = requests.get(image_url, timeout=10)\n",
        "                response.raise_for_status()\n",
        "                image = Image.open(BytesIO(response.content))\n",
        "\n",
        "                if image.mode != 'RGB':\n",
        "                    image = image.convert('RGB')\n",
        "\n",
        "                clean_image = self.transform(image)\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt == max_retries - 1:\n",
        "                    print(f\"Failed to load image after {max_retries} attempts: {image_url}\")\n",
        "                    clean_image = torch.zeros(3, 256, 256)\n",
        "                    break\n",
        "                continue\n",
        "\n",
        "\n",
        "        if self.degradation_type == 'denoise':\n",
        "            degraded_image = add_gaussian_noise(clean_image, noise_level=25)\n",
        "        elif self.degradation_type == 'dejpeg':\n",
        "            degraded_image = jpeg_compression(clean_image, quality=10)\n",
        "        elif self.degradation_type == 'super_resolution':\n",
        "            degraded_image = downsample_image(clean_image, scale_factor=4)\n",
        "            degraded_image = F.interpolate(degraded_image.unsqueeze(0),\n",
        "                                          size=clean_image.shape[1:],\n",
        "                                          mode='bicubic', align_corners=False).squeeze(0)\n",
        "        elif self.degradation_type == 'derain':\n",
        "            degraded_image = add_rain_streaks(clean_image, num_streaks=100)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown degradation type: {self.degradation_type}\")\n",
        "\n",
        "        return degraded_image, clean_image\n",
        "\n",
        "\n",
        "\n",
        "class DnCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    DnCNN: Deep Convolutional Neural Network for Image Denoising\n",
        "    IMPROVED VERSION with better stability\n",
        "    \"\"\"\n",
        "    def __init__(self, channels=3, num_layers=20, features=64):\n",
        "        super(DnCNN, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "\n",
        "\n",
        "        layers.append(nn.Conv2d(channels, features, kernel_size=3, padding=1, bias=True))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "\n",
        "        for _ in range(num_layers - 2):\n",
        "            layers.append(nn.Conv2d(features, features, kernel_size=3, padding=1, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "\n",
        "        layers.append(nn.Conv2d(features, channels, kernel_size=3, padding=1, bias=True))\n",
        "\n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        noise = self.dncnn(x)\n",
        "\n",
        "        return torch.clamp(x - noise, 0, 1)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device, clip_grad=True):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for degraded, clean in tqdm(dataloader, desc=\"Training\"):\n",
        "        degraded, clean = degraded.to(device), clean.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(degraded)\n",
        "        loss = criterion(output, clean)\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        if clip_grad:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_psnr = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for degraded, clean in tqdm(dataloader, desc=\"Validation\"):\n",
        "            degraded, clean = degraded.to(device), clean.to(device)\n",
        "\n",
        "            output = model(degraded)\n",
        "            loss = criterion(output, clean)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "\n",
        "            for i in range(output.size(0)):\n",
        "                img_pred = output[i].cpu().numpy().transpose(1, 2, 0)\n",
        "                img_clean = clean[i].cpu().numpy().transpose(1, 2, 0)\n",
        "                total_psnr += psnr(img_clean, img_pred, data_range=1.0)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_psnr = total_psnr / len(dataloader.dataset)\n",
        "\n",
        "    return avg_loss, avg_psnr\n",
        "\n",
        "\n",
        "DEGRADATION_TYPE = 'denoise'\n",
        "BATCH_SIZE = 4\n",
        "NUM_EPOCHS = 25\n",
        "LEARNING_RATE = 1e-4\n",
        "SUBSET_SIZE = 1500\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"DnCNN CPU-OPTIMIZED Training Configuration\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Model: DnCNN (20 layers)\")\n",
        "print(f\"Device: {device} (CPU-optimized)\")\n",
        "print(f\"Degradation Type: {DEGRADATION_TYPE}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE} (CPU-friendly)\")\n",
        "print(f\"Number of Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Dataset Size: {SUBSET_SIZE} (reduced for CPU)\")\n",
        "print(f\"Gradient Clipping: Enabled\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_restoration = ImageRestorationDataset(\n",
        "    train_dataset.dataset.select(train_dataset.indices),\n",
        "    degradation_type=DEGRADATION_TYPE,\n",
        "    subset_size=SUBSET_SIZE\n",
        ")\n",
        "\n",
        "val_restoration = ImageRestorationDataset(\n",
        "    val_dataset.dataset.select(val_dataset.indices),\n",
        "    degradation_type=DEGRADATION_TYPE,\n",
        "    subset_size=int(SUBSET_SIZE * 0.2) if SUBSET_SIZE else None\n",
        ")\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_restoration, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_restoration, batch_size=BATCH_SIZE,\n",
        "                        shuffle=False, num_workers=0)\n",
        "\n",
        "\n",
        "model = DnCNN(channels=3, num_layers=15, features=48).to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"Model size: {total_params * 4 / 1024 / 1024:.2f} MB\\n\")\n",
        "\n",
        "\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE,\n",
        "                            weight_decay=1e-5, betas=(0.9, 0.999))\n",
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer, T_max=NUM_EPOCHS, eta_min=1e-7\n",
        ")\n",
        "\n",
        "\n",
        "warmup_epochs = 3\n",
        "warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
        "    optimizer, start_factor=0.1, total_iters=warmup_epochs\n",
        ")\n",
        "\n",
        "\n",
        "best_psnr = 0\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "train_losses, val_losses, val_psnrs = [], [], []\n",
        "\n",
        "print(\"Starting CPU-OPTIMIZED DnCNN training...\")\n",
        "print(f\"{'='*60}\")\n",
        "print(\" CPU Training Tips:\")\n",
        "print(\"  • Smaller batch size (4) for faster processing\")\n",
        "print(\"  • Reduced dataset (500 images)\")\n",
        "print(\"  • Lighter model (15 layers, 48 features)\")\n",
        "print(\"  • Expected time: ~15-20 minutes\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
        "    print(f\"{'-'*60}\")\n",
        "\n",
        "\n",
        "    if epoch < warmup_epochs:\n",
        "        current_scheduler = warmup_scheduler\n",
        "        print(f\"[WARMUP PHASE]\")\n",
        "    else:\n",
        "        current_scheduler = scheduler\n",
        "\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device, clip_grad=True)\n",
        "    val_loss, val_psnr = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    current_scheduler.step()\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    val_psnrs.append(val_psnr)\n",
        "\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"LR: {current_lr:.6f} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val PSNR: {val_psnr:.2f} dB\")\n",
        "\n",
        "\n",
        "    if val_psnr > best_psnr:\n",
        "        improvement = val_psnr - best_psnr\n",
        "        best_psnr = val_psnr\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), 'best_dncnn_model.pth')\n",
        "        print(f\"✓ Saved best model (PSNR: {best_psnr:.2f} dB, +{improvement:.2f} dB)\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"⚠ No improvement for {patience_counter}/{patience} epochs\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\n Early stopping triggered at epoch {epoch + 1}\")\n",
        "            print(f\"Best PSNR achieved: {best_psnr:.2f} dB\")\n",
        "            break\n",
        "\n",
        "    print()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"DnCNN Training Completed!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Best PSNR: {best_psnr:.2f} dB\")\n",
        "print(f\"Total Epochs: {len(train_losses)}\")\n",
        "print(f\"Improvement over baseline: +{best_psnr - val_psnrs[0]:.2f} dB\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "ax1.plot(train_losses, label='Train Loss', linewidth=2)\n",
        "ax1.plot(val_losses, label='Val Loss', linewidth=2)\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.set_title('DnCNN OPTIMIZED: Training and Validation Loss', fontsize=14, fontweight='bold')\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax2.plot(val_psnrs, label='Val PSNR', color='green', linewidth=2, marker='o')\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('PSNR (dB)', fontsize=12)\n",
        "ax2.set_title('DnCNN OPTIMIZED: Validation PSNR', fontsize=14, fontweight='bold')\n",
        "ax2.axhline(y=best_psnr, color='r', linestyle='--', alpha=0.5, label=f'Best: {best_psnr:.2f} dB')\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load('best_dncnn_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "\n",
        "num_samples = 4\n",
        "fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
        "\n",
        "print(\"Testing OPTIMIZED DnCNN on sample images...\")\n",
        "with torch.no_grad():\n",
        "    for i in range(num_samples):\n",
        "        degraded, clean = val_restoration[i]\n",
        "        degraded_input = degraded.unsqueeze(0).to(device)\n",
        "        restored = model(degraded_input).squeeze(0).cpu()\n",
        "\n",
        "        # Convert to numpy for display\n",
        "        degraded_np = degraded.numpy().transpose(1, 2, 0)\n",
        "        clean_np = clean.numpy().transpose(1, 2, 0)\n",
        "        restored_np = restored.numpy().transpose(1, 2, 0)\n",
        "\n",
        "        # Calculate metrics\n",
        "        psnr_degraded = psnr(clean_np, degraded_np, data_range=1.0)\n",
        "        psnr_restored = psnr(clean_np, restored_np, data_range=1.0)\n",
        "        ssim_degraded = ssim(clean_np, degraded_np, data_range=1.0, channel_axis=2)\n",
        "        ssim_restored = ssim(clean_np, restored_np, data_range=1.0, channel_axis=2)\n",
        "\n",
        "        # Plot\n",
        "        axes[i, 0].imshow(np.clip(degraded_np, 0, 1))\n",
        "        axes[i, 0].set_title(f'Degraded\\nPSNR: {psnr_degraded:.2f} dB | SSIM: {ssim_degraded:.3f}',\n",
        "                            fontsize=11)\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        axes[i, 1].imshow(np.clip(restored_np, 0, 1))\n",
        "        axes[i, 1].set_title(f'DnCNN Restored\\nPSNR: {psnr_restored:.2f} dB (+{psnr_restored-psnr_degraded:.2f}) | SSIM: {ssim_restored:.3f}',\n",
        "                            fontsize=11, fontweight='bold', color='green')\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        axes[i, 2].imshow(np.clip(clean_np, 0, 1))\n",
        "        axes[i, 2].set_title('Ground Truth', fontsize=11)\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DnCNN CPU-OPTIMIZED - PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"✓ Model: DnCNN (15 layers, CPU-optimized)\")\n",
        "print(f\"✓ Parameters: {trainable_params:,} (~{trainable_params/1e6:.1f}M)\")\n",
        "print(f\"✓ Device: {device}\")\n",
        "print(f\"✓ Task: {DEGRADATION_TYPE}\")\n",
        "print(f\"✓ Best PSNR: {best_psnr:.2f} dB\")\n",
        "print(f\"✓ Training Epochs: {len(train_losses)}\")\n",
        "print(f\"✓ Training Data: {SUBSET_SIZE} images\")\n",
        "print(f\"✓ Model saved as: best_dncnn_model.pth\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n CPU OPTIMIZATIONS APPLIED:\")\n",
        "print(\"  • Reduced model size: 20→15 layers, 64→48 features\")\n",
        "print(\"  • Smaller batch size: 8→4\")\n",
        "print(\"  • Less data: 5000→500 images\")\n",
        "print(\"  • Fewer epochs: 50→25\")\n",
        "print(\"  • No multiprocessing (num_workers=0)\")\n",
        "print(\"  • Memory efficient settings\")\n",
        "print(\"=\"*60)"
      ]
    }
  ]
}