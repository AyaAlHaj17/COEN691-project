{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e6d465",
   "metadata": {},
   "source": [
    "# HQ-50K EDA Notebook (Image Restoration)\n",
    "\n",
    "This notebook performs an exploratory data analysis (EDA) of the **HQ-50K** dataset for image restoration tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c71c7",
   "metadata": {},
   "source": [
    "> **References**\n",
    "> - GitHub repo: https://github.com/littleYaang/HQ-50K  \n",
    "> - Dataset: https://huggingface.co/datasets/YangQiee/HQ-50K  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ce1ce",
   "metadata": {},
   "source": [
    "## 0. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b399ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.5 (main, Jun 25 2025, 18:55:22) [GCC 14.2.0]\n",
      "NumPy: 2.2.6\n",
      "Pandas: 2.3.3\n",
      "PIL: 12.0.0\n",
      "OpenCV present: True\n",
      "imagehash present: True\n",
      "SciPy FFT present: True\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# %pip install pillow numpy pandas matplotlib tqdm opencv-python imagehash scipy --quiet\n",
    "\n",
    "import os, sys, math, json, random, glob, hashlib, itertools, shutil, io\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "except Exception as e:\n",
    "    cv2 = None\n",
    "\n",
    "try:\n",
    "    import imagehash\n",
    "except Exception as e:\n",
    "    imagehash = None\n",
    "\n",
    "try:\n",
    "    from scipy.fft import fft2, fftshift\n",
    "except Exception as e:\n",
    "    fft2 = None\n",
    "    fftshift = None\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "print(\"PIL:\", Image.__version__)\n",
    "print(\"OpenCV present:\", cv2 is not None)\n",
    "print(\"imagehash present:\", imagehash is not None)\n",
    "print(\"SciPy FFT present:\", fft2 is not None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca554d",
   "metadata": {},
   "source": [
    "%pip install -q datasets img2dataset pillow numpy pandas matplotlib tqdm opencv-python imagehash scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b909823-69be-4c58-aee3-da42e029e6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_ROOT: data/HQ-50K\n",
      "OUT_DIR: ./eda_output\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# path written in Linux format\n",
    "DATASET_ROOT = os.environ.get(\"HQ50K_ROOT\", r\"data/HQ-50K\")  \n",
    "OUT_DIR = os.environ.get(\"HQ50K_EDA_OUT\", \"./eda_output\")\n",
    "\n",
    "os.makedirs(DATASET_ROOT, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"DATASET_ROOT:\", DATASET_ROOT)\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "\n",
    "SUBFOLDERS = [\"train\", \"val\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653b698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[1/3] Loading image URLs from Hugging Face …\n",
      "[1/3] Got 51250 URLs\n",
      "[2/3] Writing URL list to parquet …\n",
      "[3/3] Downloading images with img2dataset …\n",
      "Starting the downloading of this file\n",
      "Sharding file number 1 of 1 called /home/anthony/Documents/498/COEN691-project/notebooks/data/HQ-50K/hq50k_urls.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File sharded in 0 shards\n",
      "Downloading starting now, check your bandwidth speed (with bwm-ng)your cpu (with htop), and your disk usage (with iotop)!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/anthony/Documents/498/COEN691-project/venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/anthony/Documents/498/COEN691-project/venv/lib/python3.13/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/anthony/Documents/498/COEN691-project/venv/lib/python3.13/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete — images saved under data/HQ-50K\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install -q datasets img2dataset pillow numpy pandas matplotlib tqdm opencv-python imagehash scipy\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from img2dataset import download\n",
    "import os\n",
    "\n",
    "\n",
    "os.makedirs(DATASET_ROOT, exist_ok=True)\n",
    "\n",
    "print(\"[1/3] Loading image URLs from Hugging Face …\")\n",
    "ds = load_dataset(\"YangQiee/HQ-50K\", split=\"train\")\n",
    "urls = [u for u in ds[\"text\"] if isinstance(u, str)]\n",
    "print(f\"[1/3] Got {len(urls)} URLs\")\n",
    "\n",
    "print(\"[2/3] Writing URL list to parquet …\")\n",
    "parquet_path = os.path.join(DATASET_ROOT, \"hq50k_urls.parquet\")\n",
    "pd.DataFrame({\"text\": urls}).to_parquet(parquet_path, index=False)\n",
    "\n",
    "print(\"[3/3] Downloading images with img2dataset …\")\n",
    "download(\n",
    "    processes_count=8,\n",
    "    thread_count=32,\n",
    "    url_list=parquet_path,\n",
    "    input_format=\"parquet\",\n",
    "    url_col=\"text\",\n",
    "    output_folder=DATASET_ROOT,\n",
    "    output_format=\"files\",\n",
    "    number_sample_per_shard=10000,\n",
    "    save_additional_columns=None,\n",
    "    distributor=\"multiprocessing\",\n",
    "    retries=2,\n",
    "    timeout=20,\n",
    "    min_image_size=128,\n",
    "    skip_reencode=True,\n",
    ")\n",
    "print(\"Download complete — images saved under\", DATASET_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eca210",
   "metadata": {},
   "source": [
    "## 2. Scan Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12aa3db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 image files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def list_images(root, subfolders=(\"train\", \"val\")):\n",
    "    exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\", \".tif\", \".tiff\")\n",
    "    records = []\n",
    "    for sub in subfolders:\n",
    "        subpath = os.path.join(root, sub)\n",
    "        if not os.path.isdir(subpath):\n",
    "            continue\n",
    "        for path in glob.iglob(os.path.join(subpath, \"**\", \"*\"), recursive=True):\n",
    "            if path.lower().endswith(exts):\n",
    "                try:\n",
    "                    size = os.path.getsize(path)\n",
    "                except Exception:\n",
    "                    size = None\n",
    "                records.append({\"split\": sub, \"path\": path, \"size_bytes\": size})\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "df_files = list_images(DATASET_ROOT, SUBFOLDERS)\n",
    "print(\"Found\", len(df_files), \"image files\")\n",
    "df_files.sample(min(3, len(df_files)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efab21",
   "metadata": {},
   "source": [
    "## 3. Basic File Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inspect_image(path):\n",
    "    info = {\"path\": path}\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            info[\"format\"] = im.format\n",
    "            info[\"mode\"] = im.mode\n",
    "            w, h = im.size\n",
    "            info[\"width\"] = int(w)\n",
    "            info[\"height\"] = int(h)\n",
    "            info[\"aspect\"] = w / h if h else np.nan\n",
    "            info[\"megapixels\"] = (w * h) / 1e6\n",
    "            if im.format == \"JPEG\":\n",
    "                size_b = os.path.getsize(path)\n",
    "                info[\"bpp_proxy\"] = (size_b * 8) / max(1, (w * h))\n",
    "            else:\n",
    "                info[\"bpp_proxy\"] = np.nan\n",
    "    except Exception as e:\n",
    "        info[\"error\"] = str(e)\n",
    "    return info\n",
    "\n",
    "if len(df_files) > 0:\n",
    "    stats = []\n",
    "    for row in tqdm(df_files.itertuples(), total=len(df_files)):\n",
    "        stats.append(inspect_image(row.path))\n",
    "    df_stats = pd.DataFrame(stats).merge(df_files[[\"split\", \"path\", \"size_bytes\"]], on=\"path\", how=\"left\")\n",
    "else:\n",
    "    df_stats = pd.DataFrame()\n",
    "\n",
    "print(\"Images with errors:\", int(df_stats[\"error\"].notna().sum()) if not df_stats.empty else 0)\n",
    "df_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e7b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save basic stats\n",
    "if not df_stats.empty:\n",
    "    df_stats.to_csv(os.path.join(OUT_DIR, \"basic_stats.csv\"), index=False)\n",
    "    df_summary = {\n",
    "        \"n_images\": int(len(df_stats)),\n",
    "        \"by_split\": df_stats.groupby(\"split\")[\"path\"].count().to_dict(),\n",
    "        \"avg_megapixels\": float(df_stats[\"megapixels\"].mean(skipna=True)) if \"megapixels\" in df_stats else None,\n",
    "        \"median_megapixels\": float(df_stats[\"megapixels\"].median(skipna=True)) if \"megapixels\" in df_stats else None,\n",
    "        \"format_counts\": df_stats[\"format\"].value_counts(dropna=False).to_dict() if \"format\" in df_stats else {},\n",
    "        \"error_count\": int(df_stats[\"error\"].notna().sum()) if \"error\" in df_stats else 0,\n",
    "    }\n",
    "    with open(os.path.join(OUT_DIR, \"summary_basic.json\"), \"w\") as f:\n",
    "        json.dump(df_summary, f, indent=2)\n",
    "    df_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de53012",
   "metadata": {},
   "source": [
    "## 4. Distributions & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5eec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not df_stats.empty:\n",
    "    plt.figure()\n",
    "    df_stats[\"megapixels\"].dropna().clip(upper=20).hist(bins=50)\n",
    "    plt.title(\"Megapixel Distribution (clipped at 20MP)\")\n",
    "    plt.xlabel(\"MP\"); plt.ylabel(\"Count\")\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"hist_megapixels.png\"), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    df_stats[\"aspect\"].dropna().clip(lower=0.2, upper=5).hist(bins=60)\n",
    "    plt.title(\"Aspect Ratio Distribution (clipped)\")\n",
    "    plt.xlabel(\"W/H\"); plt.ylabel(\"Count\")\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"hist_aspect.png\"), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    if \"bpp_proxy\" in df_stats.columns:\n",
    "        plt.figure()\n",
    "        df_stats.loc[df_stats[\"bpp_proxy\"].notna(), \"bpp_proxy\"].clip(upper=4).hist(bins=60)\n",
    "        plt.title(\"JPEG Bits-per-Pixel (proxy)\")\n",
    "        plt.xlabel(\"bpp (approx)\"); plt.ylabel(\"Count\")\n",
    "        plt.savefig(os.path.join(OUT_DIR, \"hist_bpp_proxy.png\"), bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    df_stats[\"format\"].fillna(\"Unknown\").value_counts().plot(kind=\"bar\")\n",
    "    plt.title(\"Format Counts\"); plt.ylabel(\"Images\")\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"bar_formats.png\"), bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa1510",
   "metadata": {},
   "source": [
    "## 5. Quality Proxies: Sharpness, Brightness, Colorfulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1d0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def var_of_laplacian(img_gray):\n",
    "    if cv2 is None:\n",
    "        return np.nan\n",
    "    return cv2.Laplacian(img_gray, cv2.CV_64F).var()\n",
    "\n",
    "def brightness_and_contrast(img_gray):\n",
    "    g = np.asarray(img_gray, dtype=np.float32) / 255.0\n",
    "    return float(g.mean()), float(g.std())\n",
    "\n",
    "def colorfulness_metric(im):\n",
    "    im = np.asarray(im.convert(\"RGB\"), dtype=np.float32)\n",
    "    rg = np.abs(im[...,0]-im[...,1])\n",
    "    yb = np.abs(0.5*(im[...,0]+im[...,1]) - im[...,2])\n",
    "    std_rg, mean_rg = np.std(rg), np.mean(rg)\n",
    "    std_yb, mean_yb = np.std(yb), np.mean(yb)\n",
    "    return float(np.sqrt(std_rg**2 + std_yb**2) + 0.3*np.sqrt(mean_rg**2 + mean_yb**2))\n",
    "\n",
    "def compute_quality_metrics(row):\n",
    "    out = {\"path\": row.path}\n",
    "    try:\n",
    "        with Image.open(row.path) as im:\n",
    "            rgb = im.convert(\"RGB\")\n",
    "            gray = rgb.convert(\"L\")\n",
    "            g = np.asarray(gray)\n",
    "            out[\"sharpness_varlap\"] = var_of_laplacian(g)\n",
    "            b, c = brightness_and_contrast(gray)\n",
    "            out[\"brightness\"] = b\n",
    "            out[\"contrast\"] = c\n",
    "            out[\"colorfulness\"] = colorfulness_metric(rgb)\n",
    "    except Exception as e:\n",
    "        out[\"qm_error\"] = str(e)\n",
    "    return out\n",
    "\n",
    "if not df_stats.empty:\n",
    "    qms = []\n",
    "    for row in tqdm(df_stats.itertuples(), total=len(df_stats)):\n",
    "        qms.append(compute_quality_metrics(row))\n",
    "    df_qm = pd.DataFrame(qms)\n",
    "    df_stats = df_stats.merge(df_qm, on=\"path\", how=\"left\")\n",
    "    df_stats.to_csv(os.path.join(OUT_DIR, \"stats_with_quality.csv\"), index=False)\n",
    "\n",
    "    for col, title in [\n",
    "        (\"sharpness_varlap\", \"Variance of Laplacian (Sharpness)\"),\n",
    "        (\"brightness\", \"Brightness (0-1)\"),\n",
    "        (\"contrast\", \"Local Contrast (std of grayscale)\"),\n",
    "        (\"colorfulness\", \"Colorfulness (Hasler-Süsstrunk)\"),\n",
    "    ]:\n",
    "        plt.figure()\n",
    "        df_stats[col].dropna().clip(upper=np.percentile(df_stats[col].dropna(), 99)).hist(bins=60)\n",
    "        plt.title(title); plt.xlabel(col); plt.ylabel(\"Count\")\n",
    "        plt.savefig(os.path.join(OUT_DIR, f\"hist_{col}.png\"), bbox_inches=\"tight\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582b1d01",
   "metadata": {},
   "source": [
    "## 6. Frequency Richness (High-Frequency Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def high_frequency_ratio(im, cutoff=0.25):\n",
    "    # Compute ratio of high-frequency energy via 2D FFT.\n",
    "    # cutoff in (0,1): proportion of central (low-freq) square to ignore.\n",
    "    if fft2 is None or fftshift is None:\n",
    "        return np.nan\n",
    "    arr = np.asarray(im.convert(\"L\"), dtype=np.float32) / 255.0\n",
    "    F = fftshift(np.abs(fft2(arr)))\n",
    "    h, w = F.shape\n",
    "    cy, cx = h//2, w//2\n",
    "    r = int(min(h, w) * cutoff / 2.0)\n",
    "    mask = np.ones_like(F, dtype=bool)\n",
    "    mask[cy-r:cy+r, cx-r:cx+r] = False\n",
    "    hf = F[mask].sum()\n",
    "    total = F.sum() + 1e-8\n",
    "    return float(hf / total)\n",
    "\n",
    "def compute_hf_ratio(row):\n",
    "    out = {\"path\": row.path}\n",
    "    try:\n",
    "        with Image.open(row.path) as im:\n",
    "            out[\"hf_ratio\"] = high_frequency_ratio(im, cutoff=0.25)\n",
    "    except Exception as e:\n",
    "        out[\"hf_error\"] = str(e)\n",
    "    return out\n",
    "\n",
    "if not df_stats.empty:\n",
    "    hfs = []\n",
    "    for row in tqdm(df_stats.itertuples(), total=len(df_stats)):\n",
    "        hfs.append(compute_hf_ratio(row))\n",
    "    df_hf = pd.DataFrame(hfs)\n",
    "    df_stats = df_stats.merge(df_hf, on=\"path\", how=\"left\")\n",
    "    df_stats.to_csv(os.path.join(OUT_DIR, \"stats_with_quality_and_hf.csv\"), index=False)\n",
    "\n",
    "    plt.figure()\n",
    "    df_stats[\"hf_ratio\"].dropna().hist(bins=60)\n",
    "    plt.title(\"High-Frequency Energy Ratio\")\n",
    "    plt.xlabel(\"hf_ratio\"); plt.ylabel(\"Count\")\n",
    "    plt.savefig(os.path.join(OUT_DIR, \"hist_hf_ratio.png\"), bbox_inches=\"tight\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad81e9",
   "metadata": {},
   "source": [
    "## 7. Near-Duplicate Detection (Perceptual Hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc43820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def phash_of_image(path):\n",
    "    if imagehash is None:\n",
    "        return None\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            return str(imagehash.phash(im.convert(\"RGB\")))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "if not df_stats.empty and imagehash is not None:\n",
    "    phashes = []\n",
    "    for row in tqdm(df_stats.itertuples(), total=len(df_stats)):\n",
    "        phashes.append({\"path\": row.path, \"phash\": phash_of_image(row.path)})\n",
    "    df_ph = pd.DataFrame(phashes)\n",
    "    df_stats = df_stats.merge(df_ph, on=\"path\", how=\"left\")\n",
    "\n",
    "    dup_groups = df_stats[df_stats[\"phash\"].notna()].groupby(\"phash\")[\"path\"].apply(list)\n",
    "    dup_groups = {h: ps for h, ps in dup_groups.items() if len(ps) > 1}\n",
    "    with open(os.path.join(OUT_DIR, \"near_duplicates.json\"), \"w\") as f:\n",
    "        json.dump(dup_groups, f, indent=2)\n",
    "    print(\"Near-duplicate clusters (exact phash match):\", len(dup_groups))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c19b064",
   "metadata": {},
   "source": [
    "## 8. Visual Sampling Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0fe0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_grid(paths, out_path, cols=5, size=256):\n",
    "    imgs = []\n",
    "    for p in paths[:cols*cols]:\n",
    "        try:\n",
    "            with Image.open(p) as im:\n",
    "                im = im.convert(\"RGB\")\n",
    "                im.thumbnail((size, size))\n",
    "                imgs.append(im)\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not imgs:\n",
    "        return\n",
    "    rows = math.ceil(len(imgs)/cols)\n",
    "    grid = Image.new(\"RGB\", (cols*size, rows*size), (255,255,255))\n",
    "    for i, im in enumerate(imgs):\n",
    "        r, c = divmod(i, cols)\n",
    "        grid.paste(im, (c*size, r*size))\n",
    "    grid.save(out_path)\n",
    "\n",
    "if not df_stats.empty:\n",
    "    df_sorted = df_stats.sort_values(\"hf_ratio\")\n",
    "    low_hf_paths = df_sorted[\"path\"].head(25).tolist()\n",
    "    high_hf_paths = df_sorted[\"path\"].tail(25).tolist()\n",
    "    save_grid(low_hf_paths, os.path.join(OUT_DIR, \"grid_low_hf.png\"))\n",
    "    save_grid(high_hf_paths, os.path.join(OUT_DIR, \"grid_high_hf.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e9f1a",
   "metadata": {},
   "source": [
    "## 9. Suggested Train/Val/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02917652",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, os\n",
    "def create_split_files(df, out_dir, train_ratio=0.98, val_ratio=0.02, seed=1337):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df = df[df[\"error\"].isna()] if \"error\" in df.columns else df.copy()\n",
    "    paths = df[\"path\"].tolist()\n",
    "    rng.shuffle(paths)\n",
    "    n = len(paths)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "    split = {\n",
    "        \"train\": paths[:n_train],\n",
    "        \"val\": paths[n_train:n_train+n_val],\n",
    "        \"test\": paths[n_train+n_val:],\n",
    "    }\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for k, v in split.items():\n",
    "        with open(os.path.join(out_dir, f\"{k}.txt\"), \"w\") as f:\n",
    "            f.write(\"\\n\".join(v))\n",
    "    return split\n",
    "\n",
    "if not df_stats.empty:\n",
    "    split = create_split_files(df_stats, os.path.join(OUT_DIR, \"splits\"))\n",
    "    {k: len(v) for k, v in split.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b5fe80",
   "metadata": {},
   "source": [
    "## 10. Pair Generation for Image Restoration (Synthetic Degradations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6b498",
   "metadata": {},
   "source": [
    "We provide simple, configurable degradations to generate paired data for:\n",
    "- **Super-Resolution (SR)**: down-scale by s∈{2,3,4}, optional blur, noise, JPEG.\n",
    "- **Denoising**: add Gaussian noise (σ in [0,50]) or Poisson.\n",
    "- **deJPEG**: re-encode JPEG at low qualities (q in [10,30]).\n",
    "\n",
    "> **Note:** Deraining/dehazing typically require specialized synthesis; you can extend the pipeline accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import io, hashlib\n",
    "def ensure_dir(p):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def degrade_sr(img, scale=4, blur_sigma=0.8, noise_sigma=2.0, jpeg_q=95):\n",
    "    w, h = img.size\n",
    "    lr = img.resize((max(1,w//scale), max(1,h//scale)), Image.BICUBIC)\n",
    "    if blur_sigma and (cv2 is not None):\n",
    "        k = int(blur_sigma*4+1)//2*2+1\n",
    "        lr_np = cv2.GaussianBlur(np.array(lr), (k,k), blur_sigma)\n",
    "        lr = Image.fromarray(lr_np)\n",
    "    if noise_sigma and noise_sigma>0:\n",
    "        lr_np = np.array(lr).astype(np.float32)\n",
    "        lr_np += np.random.normal(0, noise_sigma, lr_np.shape)\n",
    "        lr_np = np.clip(lr_np, 0, 255).astype(np.uint8)\n",
    "        lr = Image.fromarray(lr_np)\n",
    "    if jpeg_q and 1 <= jpeg_q <= 100:\n",
    "        buf = io.BytesIO()\n",
    "        lr.save(buf, format=\"JPEG\", quality=int(jpeg_q))\n",
    "        buf.seek(0)\n",
    "        lr = Image.open(buf).convert(\"RGB\")\n",
    "    return lr\n",
    "\n",
    "def degrade_denoise(img, sigma=25.0, poisson=False):\n",
    "    arr = np.array(img).astype(np.float32)\n",
    "    if poisson:\n",
    "        arr01 = arr/255.0\n",
    "        noisy = np.random.poisson(arr01*255)/255.0\n",
    "        arr = np.clip(noisy*255, 0, 255).astype(np.uint8)\n",
    "    else:\n",
    "        arr += np.random.normal(0, sigma, arr.shape)\n",
    "        arr = np.clip(arr, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(arr)\n",
    "\n",
    "def degrade_dejpeg(img, quality=20):\n",
    "    buf = io.BytesIO()\n",
    "    img.save(buf, format=\"JPEG\", quality=int(quality))\n",
    "    buf.seek(0)\n",
    "    return Image.open(buf).convert(\"RGB\")\n",
    "\n",
    "def write_pair(hr_img, lr_img, base_name, out_root, task):\n",
    "    hr_dir = os.path.join(out_root, task, \"HR\")\n",
    "    lr_dir = os.path.join(out_root, task, \"LR\")\n",
    "    ensure_dir(hr_dir); ensure_dir(lr_dir)\n",
    "    hr_path = os.path.join(hr_dir, base_name + \".png\")\n",
    "    lr_path = os.path.join(lr_dir, base_name + \".png\")\n",
    "    hr_img.save(hr_path)\n",
    "    lr_img.save(lr_path)\n",
    "    return hr_path, lr_path\n",
    "\n",
    "def generate_pairs(paths, out_root=\"./pairs\", limit=None, seed=123):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    count = 0\n",
    "    for p in tqdm(paths):\n",
    "        if limit and count >= limit:\n",
    "            break\n",
    "        try:\n",
    "            with Image.open(p) as im:\n",
    "                im = im.convert(\"RGB\")\n",
    "                base = hashlib.md5(p.encode()).hexdigest()[:12]\n",
    "\n",
    "                s = int(rng.choice([2,3,4]))\n",
    "                lr = degrade_sr(im, scale=s, blur_sigma=float(rng.uniform(0.0, 1.2)),\n",
    "                                noise_sigma=float(rng.uniform(0.0, 3.0)), jpeg_q=int(rng.integers(70, 100)))\n",
    "                write_pair(im, lr, f\"sr_s{s}_{base}\", out_root, \"SR\")\n",
    "\n",
    "                if rng.random() < 0.5:\n",
    "                    lr = degrade_denoise(im, sigma=float(rng.uniform(5, 50)), poisson=False)\n",
    "                else:\n",
    "                    lr = degrade_denoise(im, sigma=0.0, poisson=True)\n",
    "                write_pair(im, lr, f\"denoise_{base}\", out_root, \"Denoise\")\n",
    "\n",
    "                q = int(rng.integers(10, 35))\n",
    "                lr = degrade_dejpeg(im, quality=q)\n",
    "                write_pair(im, lr, f\"dejpeg_q{q}_{base}\", out_root, \"DeJPEG\")\n",
    "                count += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(\"Generated pairs:\", count)\n",
    "\n",
    "if not df_stats.empty:\n",
    "    sample_paths = df_stats[\"path\"].dropna().sample(min(200, len(df_stats)), random_state=0).tolist()\n",
    "    generate_pairs(sample_paths, out_root=os.path.join(OUT_DIR, \"pairs\"), limit=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a72f0",
   "metadata": {},
   "source": [
    "## 11. Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac97e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not df_stats.empty:\n",
    "    agg = df_stats.groupby(\"split\").agg(\n",
    "        n=(\"path\",\"count\"),\n",
    "        mp_mean=(\"megapixels\",\"mean\"),\n",
    "        mp_median=(\"megapixels\",\"median\"),\n",
    "        bpp_mean=(\"bpp_proxy\",\"mean\"),\n",
    "        hf_mean=(\"hf_ratio\",\"mean\"),\n",
    "        sharp_mean=(\"sharpness_varlap\",\"mean\"),\n",
    "        bright_mean=(\"brightness\",\"mean\"),\n",
    "        contrast_mean=(\"contrast\",\"mean\"),\n",
    "        color_mean=(\"colorfulness\",\"mean\"),\n",
    "        n_errors=(\"error\", lambda s: int(s.notna().sum())),\n",
    "    )\n",
    "    agg.to_csv(os.path.join(OUT_DIR, \"summary_by_split.csv\"))\n",
    "    display(agg.head())\n",
    "\n",
    "    report = {\n",
    "        \"N\": int(len(df_stats)),\n",
    "        \"train_N\": int((df_stats[\"split\"]==\"train\").sum()),\n",
    "        \"val_N\": int((df_stats[\"split\"]==\"val\").sum()),\n",
    "        \"avg_MP\": float(df_stats[\"megapixels\"].mean(skipna=True)),\n",
    "        \"median_MP\": float(df_stats[\"megapixels\"].median(skipna=True)),\n",
    "        \"avg_bpp\": float(df_stats[\"bpp_proxy\"].mean(skipna=True)),\n",
    "        \"avg_hf_ratio\": float(df_stats[\"hf_ratio\"].mean(skipna=True)),\n",
    "        \"avg_sharp_varlap\": float(df_stats[\"sharpness_varlap\"].mean(skipna=True)),\n",
    "        \"avg_brightness\": float(df_stats[\"brightness\"].mean(skipna=True)),\n",
    "        \"avg_contrast\": float(df_stats[\"contrast\"].mean(skipna=True)),\n",
    "        \"avg_colorfulness\": float(df_stats[\"colorfulness\"].mean(skipna=True)),\n",
    "        \"errors\": int(df_stats[\"error\"].notna().sum()) if \"error\" in df_stats else 0,\n",
    "    }\n",
    "    with open(os.path.join(OUT_DIR, \"eda_report.json\"), \"w\") as f:\n",
    "        json.dump(report, f, indent=2)\n",
    "    report\n"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Generated by ChatGPT"
   }
  ],
  "created": "2025-10-23T00:10:54.364884",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
